# app.py (Streamlit - Corrig√© pour Gemini RAG)
import os
import json
import tempfile
import streamlit as st

# Importez vos modules locaux
from Text_processing import text_process
from OCR import pdf_to_text_json
from semantic_search import semantic_search_chroma
from sentence_transformers import SentenceTransformer

# --- CHANGEMENT 1 : Importer la nouvelle fonction Gemini RAG ---
# Assurez-vous que le fichier generate_answer_gemini.py est bien dans votre dossier
from generate_answer import generate_rag_answer_from_search 

# --- CONFIGURATION INITIALE & TITRE ---
st.set_page_config(layout="wide")
st.title("Chat with your PDF via Gemini ü§ñ")

# --- CHANGEMENT 2 : V√©rification de la cl√© Gemini ---
# Le SDK 'google-genai' lit automatiquement GEMINI_API_KEY.
# On v√©rifie si la cl√© est pr√©sente pour guider l'utilisateur.
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    # Optionnel : Permettre la saisie de la cl√© dans l'interface Streamlit
    GEMINI_API_KEY = st.text_input(
        "Entrez votre **GEMINI_API_KEY** :", 
        type="password",
        help="La cl√© est lue par la variable d'environnement GEMINI_API_KEY."
    )
    if not GEMINI_API_KEY:
        st.error("‚ö†Ô∏è Cl√© Gemini API requise. Veuillez la d√©finir dans l'environnement ou ci-dessus.")
        # Arr√™ter l'ex√©cution de l'application si la cl√© manque
        st.stop()
else:
    st.success("üîë Authentification Gemini API pr√™te.")


# --- INTERFACE UTILISATEUR ---
uploaded_file = st.file_uploader("D√©posez votre fichier PDF ici :", type=["pdf"])
user_prompt = st.chat_input("Posez votre question ici...")


# --- LOGIQUE PRINCIPALE ---
if uploaded_file is not None:
    # Affichage de confirmation de fichier
    st.info(f"Fichier re√ßu : {uploaded_file.name}. Traitement en cours...")

    # Sauvegarde temporaire du PDF
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    try:
        # Extraction texte via ton OCR
        with st.spinner("1/3 - Extraction du texte..."):
            temp_json_path = pdf_to_text_json(tmp_path)
            with open(temp_json_path, 'r', encoding='utf-8') as f:
                extracted_text = json.load(f)

        # Cr√©ation des chunks et du vectorstore (Chroma)
        with st.spinner("2/3 - Cr√©ation des chunks et de la base vectorielle..."):
            pdf_data = text_process(
                extracted_text,
                chunk_size=200,
                overlap=50,
                lower=True,
                apply_corrections=False,
                create_vectorstore=True,
                persist_directory=None,
                model_name='sentence-transformers/all-MiniLM-L6-v2'
            )
            collection = pdf_data["vectorstore"]

        # Si l'utilisateur a pos√© une question et que le traitement est termin√©
        if user_prompt:
            st.info("3/3 - Recherche s√©mantique en cours...")
            
            # Encoder la question
            embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
            query_embedding = embedder.encode(user_prompt).tolist()

            # Appel de la recherche s√©mantique
            search_output = semantic_search_chroma(query_embedding, collection, n_results=3)

            # Afficher les passages utilis√©s (transparence)
            with st.expander("üîç Passages de contexte trouv√©s :"):
                for i, chunk in enumerate(search_output.get("documents", []), start=1):
                    st.markdown(f"**Passage {i} (Distance: {search_output.get('distances', [None]*i)[i-1]:.4f}):**")
                    st.write(chunk)

            # G√©n√©ration RAG avec Gemini 2.5 Flash
            with st.spinner("üß† G√©n√©ration de la r√©ponse avec Gemini 2.5 Flash..."):
                answer = generate_rag_answer_from_search(
                    search_output=search_output,
                    user_prompt=user_prompt,
                    llm_model="gemini-2.5-flash" # Sp√©cification du mod√®le Gemini
                )

            st.subheader("üí¨ R√©ponse g√©n√©r√©e :")
            st.success(answer)
            
    finally:
        # Nettoyage des fichiers temporaires
        if os.path.exists(tmp_path):
            os.remove(tmp_path)
        if 'temp_json_path' in locals() and os.path.exists(temp_json_path):
            os.remove(temp_json_path)