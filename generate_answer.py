import os
from typing import Dict, List, Any
from google import genai
from google.genai.errors import APIError
from google.genai import types

def generate_rag_answer_from_search(
    search_output: Dict[str, List[str]],
    user_prompt: str,
    llm_model: str = "gemini-2.5-flash",
    temperature: float = 0.3,
    max_output_tokens: int = 512
) -> str:
    """
    G√©n√®re une r√©ponse RAG (Retrieval-Augmented Generation) √† partir de l'output
    de la recherche s√©mantique, en utilisant l'API Gemini 2.5 Flash.

    L'authentification utilise la variable d'environnement GEMINI_API_KEY.

    search_output doit √™tre un dictionnaire du type :
        {
            "documents": [...],   # liste de chunks textuels (str)
            "ids": [...],
            "distances": [...]
        }
    """

    # --- 1. Initialisation du client Gemini ---
    # Le client r√©cup√®re automatiquement la cl√© API de l'environnement GEMINI_API_KEY
    try:
        client = genai.Client()
    except Exception:
        # G√©rer le cas o√π la cl√© n'est pas d√©finie ou est invalide.
        return "‚ùå Erreur: GEMINI_API_KEY n'est pas d√©finie ou est invalide."


    # --- 2. V√©rifications minimales et pr√©paration du contexte ---
    if not search_output or "documents" not in search_output or not isinstance(search_output.get("documents"), list):
        return "‚ùå search_output invalide : cl√© 'documents' manquante ou format incorrect."

    context_chunks = search_output["documents"]
    if len(context_chunks) == 0:
        return "‚ùå Aucun chunk de contexte trouv√© par la recherche s√©mantique."

    # Construction du contexte complet, s√©par√© par des doubles sauts de ligne
    context_text = "\n\n".join(context_chunks)

    # --- 3. Cr√©ation du prompt RAG (Instructions + Contexte + Question) ---
    system_instruction = (
        "Tu es un assistant intelligent et serviable qui r√©pond **uniquement** √† partir du contexte "
        "fourni. Si la r√©ponse ne se trouve pas dans le contexte, tu dois r√©pondre "
        "poliment que l'information n'est pas disponible dans les sources fournies. "
        "Tes r√©ponses doivent √™tre concises et directes."
    )

    full_prompt = f"""
=== CONTEXTE FOURNI ===
{context_text}

=== QUESTION DE L'UTILISATEUR ===
{user_prompt}
"""

    # --- 4. Configuration de la g√©n√©ration ---
    config = types.GenerateContentConfig(
        system_instruction=system_instruction,
        temperature=temperature,
        max_output_tokens=max_output_tokens
    )

    # --- 5. Appel √† l'API Gemini ---
    try:
        response = client.models.generate_content(
            model=llm_model,
            contents=full_prompt,
            config=config
        )

        # V√©rifier si une r√©ponse valide a √©t√© g√©n√©r√©e
        if response.text:
            return response.text.strip()
        else:
            return "‚ö†Ô∏è Le mod√®le a g√©n√©r√© une r√©ponse vide ou bloqu√©e."

    except APIError as e:
        return f"‚ùå Erreur API Gemini ({e.status_code}) : {e.message}"
    except Exception as e:
        return f"‚ùå Erreur inattendue lors de l'appel √† Gemini : {e}"

# ----------------------------------------------------------------------
# --- EXEMPLE D'UTILISATION (Pour tester la fonction) ---
# ----------------------------------------------------------------------

if __name__ == "__main__":
    # Assurez-vous que la variable GEMINI_API_KEY est d√©finie dans votre environnement
    if "GEMINI_API_KEY" not in os.environ:
        print("üö® VEUILLEZ D√âFINIR LA VARIABLE D'ENVIRONNEMENT 'GEMINI_API_KEY'")
    else:
        # Simulation de l'output d'une recherche s√©mantique (RAG)
        simulated_search_output: Dict[str, List[str]] = {
            "documents": [
                "Le langage Python, cr√©√© par Guido van Rossum, est sorti pour la premi√®re fois en 1991. Il est tr√®s appr√©ci√© pour sa lisibilit√© et sa syntaxe claire.",
                "Gemini 2.5 Flash est un mod√®le multimodal con√ßu pour la rapidit√© et l'efficacit√©, avec une fen√™tre contextuelle d'un million de jetons."
            ],
            "ids": ["doc_1", "doc_2"],
            "distances": [0.15, 0.22]
        }
        
        user_question = "Qui est le cr√©ateur du langage Python et quand a-t-il √©t√© publi√© ?"

        print(f"Question : {user_question}")
        print("G√©n√©ration de la r√©ponse RAG avec Gemini 2.5 Flash...")
        
        answer = generate_rag_answer_from_search(
            search_output=simulated_search_output,
            user_prompt=user_question,
            temperature=0.1 # Temp√©rature basse pour une r√©ponse plus factuelle/d√©termin√©e
        )
        
        print("\n=== R√âPONSE FINALE DU MOD√àLE ===")
        print(answer)
        print("================================")